{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stage 1: preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gensim\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from rus_preprocessing_udpipe import *\n",
    "from tqdm import tqdm_notebook as tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv('train_sq.tsv', sep=r'\\t', header=None, engine='python')\n",
    "train_df.columns = ['ID', 'Title', 'Content', 'Target']\n",
    "train_df.dropna(inplace=True)\n",
    "\n",
    "# fix index\n",
    "train_df.index = pd.Index(range(len(train_df)))\n",
    "\n",
    "# get class targets\n",
    "for i in range(100):\n",
    "    train_df[f'Class {i}'] = train_df['Target'].apply(lambda classes: str(i) in classes.split(',')).astype(np.int8)\n",
    "    \n",
    "\n",
    "test_df = pd.read_csv('test_sq.tsv', sep=r'\\t', header=None, engine='python')\n",
    "test_df.columns = ['ID', 'Title', 'Content']\n",
    "test_df.dropna(inplace=True)\n",
    "\n",
    "# fix index\n",
    "test_df.index = pd.Index(range(len(test_df)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Loading the model...\n"
     ]
    }
   ],
   "source": [
    "standard_library.install_aliases()\n",
    "\n",
    "# URL of the UDPipe model\n",
    "udpipe_model_url = 'https://rusvectores.org/static/models/udpipe_syntagrus.model'\n",
    "udpipe_filename = udpipe_model_url.split('/')[-1]\n",
    "\n",
    "if not os.path.isfile(udpipe_filename):\n",
    "    print('UDPipe model not found. Downloading...', file=sys.stderr)\n",
    "    wget.download(udpipe_model_url)\n",
    "\n",
    "print('\\nLoading the model...', file=sys.stderr)\n",
    "udpipe_model = Model.load(udpipe_filename)\n",
    "process_pipeline = Pipeline(udpipe_model, 'tokenize', Pipeline.DEFAULT, Pipeline.DEFAULT, 'conllu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "word2vec_model = gensim.models.KeyedVectors.load(\"model.model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing train data...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eae7beba04414068aa6c6fdf3918cad0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=125931), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "train_udp_titles = []\n",
    "print('Processing train data...', file=sys.stderr)\n",
    "for line in tqdm(train_df['Title'].values):\n",
    "    res = unify_sym(line.strip())\n",
    "    output = process(process_pipeline, text=res)\n",
    "    train_udp_titles.append(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1b9997971fbb48369799c86f53cc69a3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=125931), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "train_title_vec = []\n",
    "for title in tqdm(train_udp_titles):\n",
    "    words_vec = []\n",
    "    for word in title:\n",
    "        if word in word2vec_model:\n",
    "            words_vec.append(word2vec_model.word_vec(word))\n",
    "            \n",
    "    train_title_vec.append(words_vec)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stage 2: train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.callbacks import Callback, EarlyStopping, ModelCheckpoint\n",
    "from keras.preprocessing import sequence\n",
    "from keras.optimizers import Adam\n",
    "from keras.models import Sequential\n",
    "from keras.layers import LSTM, Dense, Dropout\n",
    "\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "SEED = 42"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class F1(Callback):\n",
    "    def on_train_begin(self, logs={}):\n",
    "        self.val_f1s = []\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs={}):\n",
    "        val_predict = (np.asarray(self.model.predict(self.validation_data[0])))\n",
    "        val_predict /= np.sum(val_predict, axis=1, keepdims=True)\n",
    "        val_predict = np.where(val_predict > 0.1, 1, 0)\n",
    "        val_targ = self.validation_data[1]\n",
    "        \n",
    "        _val_f1 = f1_score(val_targ, val_predict, average='samples')\n",
    "        self.val_f1s.append(_val_f1)\n",
    "        print (\"— val_f1: {}\".format(_val_f1))\n",
    "\n",
    "        return\n",
    "    \n",
    "f1_metric = F1()\n",
    "es = EarlyStopping()\n",
    "mc = ModelCheckpoint('./model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(LSTM(512, return_sequences=True, input_shape=(None, 300)))\n",
    "model.add(LSTM(256, return_sequences=True))\n",
    "model.add(LSTM(128, return_sequences=True))\n",
    "model.add(LSTM(64))\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dense(100, activation='sigmoid'))\n",
    "\n",
    "model.compile(Adam(), loss='categorical_crossentropy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_4 (LSTM)                (None, None, 512)         1665024   \n",
      "_________________________________________________________________\n",
      "lstm_5 (LSTM)                (None, None, 256)         787456    \n",
      "_________________________________________________________________\n",
      "lstm_6 (LSTM)                (None, None, 128)         197120    \n",
      "_________________________________________________________________\n",
      "lstm_7 (LSTM)                (None, 64)                49408     \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 128)               8320      \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 128)               16512     \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 100)               12900     \n",
      "=================================================================\n",
      "Total params: 2,736,740\n",
      "Trainable params: 2,736,740\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "maxlen = 0\n",
    "for ind, i in enumerate(train_title_vec):\n",
    "    maxlen = max(maxlen, len(i))\n",
    "    \n",
    "X_train = train_title_vec\n",
    "for ind, i in enumerate(X_train):\n",
    "    if len(i) < maxlen:\n",
    "        while len(X_train[ind]) < maxlen:\n",
    "            X_train[ind].append([0 for _ in range(300)])\n",
    "    else:\n",
    "        if len(i) > maxlen:\n",
    "            X_train[ind] = X_train[ind][:maxlen]\n",
    "            \n",
    "X_train = np.asarray(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = train_df.loc[:, [f'Class {i}' for i in range(100)]].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train,\n",
    "                                                  random_state=SEED,\n",
    "                                                  test_size=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W1120 13:03:55.587251 4563666368 deprecation.py:323] From /Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/tensorflow/python/ops/math_grad.py:1250: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "W1120 13:04:43.145566 4563666368 deprecation_wrapper.py:119] From /Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:986: The name tf.assign_add is deprecated. Please use tf.compat.v1.assign_add instead.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 113337 samples, validate on 12594 samples\n",
      "Epoch 1/30\n",
      "113337/113337 [==============================] - 1714s 15ms/step - loss: 8.3771 - val_loss: 7.9795\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in samples with no predicted labels.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "— val_f1: 0.03559707192389422\n",
      "Epoch 2/30\n",
      "113337/113337 [==============================] - 685s 6ms/step - loss: 7.4516 - val_loss: 6.8640\n",
      "— val_f1: 0.15444518118410447\n",
      "Epoch 3/30\n",
      "113337/113337 [==============================] - 667s 6ms/step - loss: 6.5706 - val_loss: 6.2785\n",
      "— val_f1: 0.2881502445818787\n",
      "Epoch 4/30\n",
      "113337/113337 [==============================] - 663s 6ms/step - loss: 6.0839 - val_loss: 5.9349\n",
      "— val_f1: 0.3485215620756354\n",
      "Epoch 5/30\n",
      "113337/113337 [==============================] - 662s 6ms/step - loss: 5.7425 - val_loss: 5.7590\n",
      "— val_f1: 0.38038609662001754\n",
      "Epoch 6/30\n",
      "113337/113337 [==============================] - 652s 6ms/step - loss: 5.4707 - val_loss: 5.6377\n",
      "— val_f1: 0.40424775760649984\n",
      "Epoch 7/30\n",
      "113337/113337 [==============================] - 662s 6ms/step - loss: 5.2331 - val_loss: 5.6120\n",
      "— val_f1: 0.42008788416601667\n",
      "Epoch 8/30\n",
      "113337/113337 [==============================] - 667s 6ms/step - loss: 5.0021 - val_loss: 5.5649\n",
      "— val_f1: 0.42941841124308966\n",
      "Epoch 9/30\n",
      "113337/113337 [==============================] - 673s 6ms/step - loss: 4.7830 - val_loss: 5.6257\n",
      "— val_f1: 0.4341091667318442\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x204e3e2b0>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train, y_train,\n",
    "          validation_data=(X_val, y_val),\n",
    "          callbacks=[f1_metric, es, mc],\n",
    "          batch_size=128,\n",
    "          epochs=30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stage 3: make predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing input...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2159268ffaa9428a931bfae337742763",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=31345), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "test_udp_titles = []\n",
    "print('Processing input...', file=sys.stderr)\n",
    "for line in tqdm(test_df['Title'].values):\n",
    "    res = unify_sym(line.strip())\n",
    "    output = process(process_pipeline, text=res)\n",
    "    test_udp_titles.append(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b606f11835824906b437c7652ceac4de",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=31345), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "test_title_vec = []\n",
    "for title in tqdm(test_udp_titles):\n",
    "    words_vec = []\n",
    "    for word in title:\n",
    "        if word in word2vec_model:\n",
    "            words_vec.append(word2vec_model.word_vec(word))\n",
    "            \n",
    "    test_title_vec.append(words_vec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = test_title_vec\n",
    "for ind, i in enumerate(X_test):\n",
    "    if len(i) < maxlen:\n",
    "        while len(X_test[ind]) < maxlen:\n",
    "            X_test[ind].append([0 for _ in range(300)])\n",
    "    else:\n",
    "        if len(i) > maxlen:\n",
    "            X_test[ind] = X_test[ind][:maxlen]\n",
    "            \n",
    "X_test = np.asarray(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_pred(preds):\n",
    "    result = []\n",
    "    for tmp in preds:\n",
    "        tmp /= np.sum(tmp)\n",
    "        tmp = [ind for ind, x in enumerate(tmp) if x > 0.1]\n",
    "        if len(tmp) == 0:\n",
    "            tmp = [0]\n",
    "        tmp = ','.join(map(str, tmp))\n",
    "        result.append(tmp)\n",
    "        \n",
    "    return result\n",
    "\n",
    "ids = list(test_df['ID'].astype(np.int32))\n",
    "pred = model.predict(X_test)\n",
    "pred = get_pred(pred)\n",
    "\n",
    "# fix missing ids\n",
    "ids_set = set(ids)\n",
    "for i in range(126048, 126048 + 31512):\n",
    "    if i not in ids_set:\n",
    "        ids.append(i)\n",
    "        pred.append('0')\n",
    "        \n",
    "submit = pd.DataFrame({'ID': ids,\n",
    "                       'pred': pred})\n",
    "submit.to_csv('submit.tsv', header=None, index=None, sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>pred</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>126048</td>\n",
       "      <td>1,11,16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>126049</td>\n",
       "      <td>2,10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>126050</td>\n",
       "      <td>0,4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>126051</td>\n",
       "      <td>18,69</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>126052</td>\n",
       "      <td>3,7</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       ID     pred\n",
       "0  126048  1,11,16\n",
       "1  126049     2,10\n",
       "2  126050      0,4\n",
       "3  126051    18,69\n",
       "4  126052      3,7"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submit.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
